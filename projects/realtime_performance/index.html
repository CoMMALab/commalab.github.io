<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Real-time Performance | CoMMA Lab @ Purdue </title> <meta name="author" content=" "> <meta name="description" content="The Computational Robot Motion and Autonomy Lab at Purdue University "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://commalab.github.io/projects/realtime_performance/"> <script src="/assets/js/theme.js?ca131c86afeddc68f0e9d3278afbc9b8"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> CoMMA Lab @ Purdue </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code </a> </li> <li class="nav-item "> <a class="nav-link" href="/classes/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/join">Join </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Real-time Performance</h1> <p class="post-description"></p> </header> <div class="big-profile float-right"> <figure> <video src="/assets/video/fast_planning.webm" class="img-fluid z-depth-1" width="100%" height="auto" autoplay controls loop muted></video> </figure> </div> <article> <p>Time and tide wait for no one.</p> <p>In the real world, people and objects will move around the environment, the world will change, and a robot cannot stay stationary and wait, scratching its head to think of what to do. It is essential for critical robotics algorithms that guarantee safety and liveness (<em>i.e.</em>, will be able to reach the goal) to be able to <em>react</em> immediately to changing circumstances. Autonomous cars must make decisions that determine the safety of their passengers and the world around them, mobile manipulators working in a factory or a warehouse may need to dodge unseen people and obstacles, and surgical robots must maintain patient safety at all times.</p> <p>Algorithms that provide real-time performance can come through theoretical properties (guaranteeing a solution in a fixed amount of computation) or software/hardware engineering (using implementation or platform-specific features to accelerate algorithms).</p> </article> <br style="clear:both"> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <a name="huangjadhav2025prrtc" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <div> arXiv </div> </abbr> </div> <div class="col-sm-10"> <div class="title">pRRTC: GPU-Parallel RRT-Connect for Fast, Consistent, and Low-Cost Motion Planning</div> <div class="author"> Chih H. Huang<sup>*</sup>, <a href="/members/jadhav">Pranav Jadhav<sup>*</sup></a>, <a href="https://brianplancher.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Brian Plancher</a>, and <a href="/members/kingston">Zachary Kingston</a> </div> <div class="periodical"> </div> <div class="periodical"> Under Review </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2503.06757" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/CoMMALab/pRRTC" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Sampling-based motion planning algorithms, like the Rapidly-Exploring Random Tree (RRT) and its widely used variant, RRT-Connect, provide efficient solutions for high-dimensional planning problems faced by real-world robots. However, these methods remain computationally intensive, particularly in complex environments that require many collision checks. As such, to improve performance, recent efforts have explored parallelizing specific components of RRT, such as collision checking or running multiple planners independently, but no prior work has integrated parallelism at multiple levels of the algorithm for robotic manipulation. In this work, we present pRRTC, a GPU-accelerated implementation of RRT-Connect that achieves parallelism across the entire algorithm through multithreaded expansion and connection, SIMT-optimized collision checking, and hierarchical parallelism optimization, improving efficiency, consistency, and initial solution cost. We evaluate the effectiveness of pRRTC on the MotionBenchMaker dataset using robots with 7, 8, and 14 degrees-of-freedom, demonstrating up to 6x average speedup on constrained reaching tasks at high collision checking resolution compared to state-of-the-art. pRRTC also demonstrates a 5x reduction in solution time variance and 1.5x improvement in initial path costs compared to state-of-the-art motion planners in complex environments across all robots.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">huangjadhav2025prrtc</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{pRRTC}: {GPU}-Parallel {RRT}-Connect for Fast, Consistent, and Low-Cost Motion Planning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chih H. and Jadhav, Pranav and Plancher, Brian and Kingston, Zachary}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2503.06757}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.RO}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Under Review}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="wilson2024fcit" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#daaa00"> <a href="https://ieee-icra.org" rel="external nofollow noopener" target="_blank"> ICRA </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Nearest-Neighbourless Asymptotically Optimal Motion Planning with Fully Connected Informed Trees (FCIT*)</div> <div class="author"> Tyler S. Wilson, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason</a>, <a href="/members/kingston">Zachary Kingston</a>, <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a>, and <a href="https://robotic-esp.com/people/gammell/" class="nonmember" rel="external nofollow noopener" target="_blank">Jonathan D. Gammell</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation</em> </div> <div class="periodical"> To Appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2411.17902" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=Lb_5Znpcleg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://robotic-esp.com/code/fcitstar/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Improving the performance of motion planning algorithms for high-degree-of-freedom robots usually requires reducing the cost or frequency of computationally expensive operations. Traditionally, and especially for asymptotically optimal sampling-based motion planners, the most expensive operations are local motion validation and querying the nearest neighbours of a configuration. Recent advances have significantly reduced the cost of motion validation by using single instruction/multiple data (SIMD) parallelism to improve solution times for satisficing motion planning problems. These advances have not yet been applied to asymptotically optimal motion planning. This paper presents Fully Connected Informed Trees (FCIT*), the first fully connected, informed, anytime almost-surely asymptotically optimal (ASAO) algorithm. FCIT* exploits the radically reduced cost of edge evaluation via SIMD parallelism to build and search fully connected graphs. This removes the need for nearest-neighbours structures, which are a dominant cost for many sampling-based motion planners, and allows it to find initial solutions faster than state-of-the-art ASAO (VAMP, OMPL) and satisficing (OMPL) algorithms on the MotionBenchMaker dataset while converging towards optimal plans in an anytime manner.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wilson2024fcit</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nearest-Neighbourless Asymptotically Optimal Motion Planning with Fully Connected Informed Trees ({FCIT}*)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wilson, Tyler S. and Thomason, Wil and Kingston, Zachary and Kavraki, Lydia E. and Gammell, Jonathan D.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2411.17902}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.RO}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <a name="liang2024ropras" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#e33900"> <a href="http://ifrr.org/isrr" rel="external nofollow noopener" target="_blank"> ISRR </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Scaling Long-Horizon Online POMDP Planning via Rapid State Space Sampling</div> <div class="author"> Yuanchu Liang<sup>*</sup>, Edward Kim<sup>*</sup>, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, <a href="https://comp.anu.edu.au/people/hanna-kurniawati/" class="nonmember" rel="external nofollow noopener" target="_blank">Hanna Kurniawati</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In International Symposium of Robotics Research</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2411.07032" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Partially Observable Markov Decision Processes (POMDPs) are a general and principled framework for motion planning under uncertainty. Despite tremendous improvement in the scalability of POMDP solvers, long-horizon POMDPs (e.g., ≥15 steps) remain difficult to solve. This paper proposes a new approximate online POMDP solver, called Reference-Based Online POMDP Planning via Rapid State Space Sampling (ROP-RaS3). ROP-RaS3 uses novel extremely fast sampling-based motion planning techniques to sample the state space and generate a diverse set of macro actions online which are then used to bias belief-space sampling and infer high-quality policies without requiring exhaustive enumeration of the action space—a fundamental constraint for modern online POMDP solvers. ROP-RaS3 is evaluated on various long-horizon POMDPs, including on a problem with a planning horizon of more than 100 steps and a problem with a 15-dimensional state space that requires more than 20 look ahead steps. In all of these problems, ROP-RaS3 substantially outperforms other state-of-the-art methods by up to multiple folds.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liang2024ropras</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scaling Long-Horizon Online {POMDP} Planning via Rapid State Space Sampling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liang, Yuanchu and Kim, Edward and Thomason, Wil and Kingston, Zachary and Kurniawati, Hanna and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Symposium of Robotics Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="ramsey2024" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA7900"> <a href="https://roboticsconference.org/" rel="external nofollow noopener" target="_blank"> RSS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Collision-Affording Point Trees: SIMD-Amenable Nearest Neighbors for Fast Collision Checking</div> <div class="author"> <a href="https://claytonwramsey.com" class="nonmember" rel="external nofollow noopener" target="_blank">Clayton W. Ramsey</a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In Robotics: Science and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.02807" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=BzDKdrU1VpM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://claytonwramsey.com/blog/captree" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/kavrakilab/vamp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.15607/RSS.2024.XX.038" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Motion planning against sensor data is often a critical bottleneck in real-time robot control. For sampling-based motion planners, which are effective for high-dimensional systems such as manipulators, the most time-intensive component is collision checking. We present a novel spatial data structure, the collision-affording point tree (CAPT): an exact representation of point clouds that accelerates collision-checking queries between robots and point clouds by an order of magnitude, with an average query time of less than 10 nanoseconds on 3D scenes comprising thousands of points. With the CAPT, sampling-based planners can generate valid, high-quality paths in under a millisecond, with total end-to-end computation time faster than 60 FPS, on a single thread of a consumer-grade CPU. We also present a point cloud filtering algorithm, based on space-filling curves, which reduces the number of points in a point cloud while preserving structure. Our approach enables robots to plan at real-time speeds in sensed environments, opening up potential uses of planning for high-dimensional systems in dynamic, changing, and unmodeled environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ramsey2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramsey, Clayton W. and Kingston, Zachary and Thomason, Wil and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collision-Affording Point Trees: SIMD-Amenable Nearest Neighbors for Fast Collision Checking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Robotics: Science and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15607/RSS.2024.XX.038}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="thomason2024vamp" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#daaa00"> <a href="https://ieee-icra.org" rel="external nofollow noopener" target="_blank"> ICRA </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Motions in Microseconds via Vectorized Sampling-Based Planning</div> <div class="author"> <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.14545" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/kavrakilab/vamp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/ICRA57147.2024.10611190" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Modern sampling-based motion planning algorithms typically take between hundreds of milliseconds to dozens of seconds to find collision-free motions for high degree-of-freedom problems. This paper presents performance improvements of more than 500x over the state-of-the-art, bringing planning times into the range of microseconds and solution rates into the range of kilohertz, without specialized hardware. Our key insight is how to exploit fine-grained parallelism within sampling-based planners, providing generality-preserving algorithmic improvements to any such planner and significantly accelerating critical subroutines, such as forward kinematics and collision checking. We demonstrate our approach over a diverse set of challenging, realistic problems for complex robots ranging from 7 to 14 degrees-of-freedom. Moreover, we show that our approach does not require high-power hardware by also evaluating on a low-power single-board computer. The planning speeds demonstrated are fast enough to reside in the range of control frequencies and open up new avenues of motion planning research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">thomason2024vamp</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Thomason, Wil and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Motions in Microseconds via Vectorized Sampling-Based Planning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8749--8756}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA57147.2024.10611190}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="Ramsey2024wksp" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#505050"> <div> Workshop </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Dynamic Motion Planning from Perception via Accelerated Point Cloud Collision Checking</div> <div class="author"> <a href="https://claytonwramsey.com" class="nonmember" rel="external nofollow noopener" target="_blank">Clayton W. Ramsey</a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE ICRA 2024 Workshop—Agile Robotics: From Perception to Dynamic Action</em> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Ramsey2024wksp</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramsey, Clayton W. and Kingston, Zachary and Thomason, Wil and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Motion Planning from Perception via Accelerated Point Cloud Collision Checking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE ICRA 2024 Workshop---Agile Robotics: From Perception to Dynamic Action}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <a name="moll2021hyper" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA9200"> <a href="https://ieee-iros.org/" rel="external nofollow noopener" target="_blank"> IROS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization</div> <div class="author"> <a href="https://moll.ai/" class="nonmember" rel="external nofollow noopener" target="_blank">Mark Moll</a>, <a href="https://cchamzas.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Constantinos Chamzas</a>, <a href="/members/kingston">Zachary Kingston</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://kavrakilab.org/publications/moll2021hyperplan.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/hyperplan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/IROS51168.2021.9636651" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Over the years, many motion planning algorithms have been proposed. It is often unclear which algorithm might be best suited for a particular class of problems. The problem is compounded by the fact that algorithm performance can be highly dependent on parameter settings. This paper shows that hyperparameter optimization is an effective tool in both algorithm selection and parameter tuning over a given set of motion planning problems. We present different loss functions for optimization that capture different notions of optimality. The approach is evaluated on a broad range of scenes using two different manipulators, a Fetch and a Baxter. We show that optimized planning algorithm performance significantly improves upon baseline performance and generalizes broadly in the sense that performance improvements carry over to problems that are very different from the ones considered during optimization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">moll2021hyper</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moll, Mark and Chamzas, Constantinos and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2511-2518}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636651}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> CoMMA Lab @ <a href="https://www.purdue.edu/" rel="external nofollow noopener" target="_blank">Purdue University</a>, <a href="https://www.cs.purdue.edu/" rel="external nofollow noopener" target="_blank">Department of Computer Science</a>. © Copyright 2025. Last updated: March 17, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>