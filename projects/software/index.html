<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Robotics Software | CoMMA Lab @ Purdue </title> <meta name="author" content=" "> <meta name="description" content="The Computational Robot Motion and Autonomy Lab at Purdue University "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://commalab.github.io/projects/software/"> <script src="/assets/js/theme.js?ca131c86afeddc68f0e9d3278afbc9b8"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> CoMMA Lab @ Purdue </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code </a> </li> <li class="nav-item "> <a class="nav-link" href="/classes/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/join">Join </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Robotics Software</h1> <p class="post-description"></p> </header> <div class="big-profile float-right"> <figure> <video src="/assets/video/software.webm" class="img-fluid z-depth-1" width="100%" height="auto" autoplay controls loop muted></video> </figure> </div> <article> <p>Modern robots are complex computer systems involving enormous amounts of software to handle everything from drivers to communicate to physical interfaces, middleware to communicate between disparate processes, and machine learning kernels to process incoming data to make decisions in real-time. Robots’ unique challenges (heterogeneous hardware, programmed and learned components, handling physical environments, emergent behavior in the real world, etc.) merit special consideration from the software used by practitioners and researchers. Developing software components, libraries, and robot systems requires understanding and shaping code around these distinguishing use cases.</p> </article> <br style="clear:both"> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <a name="coumar2025foam" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <div> arXiv </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Foam: A Tool for Spherical Approximation of Robot Geometry</div> <div class="author"> Sai Coumar, <a href="/members/chang">Gilbert Chang</a>, <a href="/members/kodkani">Nihar Kodkani</a>, and <a href="/members/kingston">Zachary Kingston</a> </div> <div class="periodical"> </div> <div class="periodical"> Under Review </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2503.13704" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/CoMMALab/foam" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Many applications in robotics require primitive spherical geometry, especially in cases where efficient distance queries are necessary. Manual creation of spherical models is time-consuming and prone to errors. This paper presents Foam, a tool to generate spherical approximations of robot geometry from an input Universal Robot Description Format (URDF) file. Foam provides a robust preprocessing pipeline to handle mesh defects and a number of configuration parameters to control the level and approximation of the spherization, and generates an output URDF with collision geometry specified only by spheres. We demonstrate Foam on a number of standard robot models on common tasks, and demonstrate improved collision checking and distance query performance with only a minor loss in fidelity compared to the true collision geometry. We release our tool as an open source Python library and containerized command-line application to facilitate adoption across the robotics community.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">coumar2025foam</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Foam: A Tool for Spherical Approximation of Robot Geometry}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Coumar, Sai and Chang, Gilbert and Kodkani, Nihar and Kingston, Zachary}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2503.13704}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.RO}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Under Review}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="agrawal2025mrangler" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009dc4"> <div> OCEANS </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Underwater Multi-Robot Simulation and Motion Planning in Angler</div> <div class="author"> <a href="https://www.akshayaagrawal.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Akshaya Agrawal</a>, Evan Palmer, <a href="/members/kingston">Zachary Kingston</a>, and <a href="https://engineering.oregonstate.edu/people/geoff-hollinger" class="nonmember" rel="external nofollow noopener" target="_blank">Geoffrey A. Hollinger</a> </div> <div class="periodical"> <em>In IEEE/MTS OCEANS Conference</em> </div> <div class="periodical"> To Appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2506.06612" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Deploying multi-robot systems in underwater environments is expensive and lengthy; testing algorithms and software in simulation improves development by decoupling software and hardware. However, this requires a simulation framework that closely resembles the real-world. Angler is an open-source framework that simulates low-level communication protocols for an onboard autopilot, such as ArduSub, providing a framework that is close to reality, but unfortunately lacking support for simulating multiple robots. We present an extension to Angler that supports multi-robot simulation and motion planning. Our extension has a modular architecture that creates non-conflicting communication channels between Gazebo, ArduSub Software-in-the-Loop (SITL), and MAVROS to operate multiple robots simultaneously in the same environment. Our multi-robot motion planning module interfaces with cascaded controllers via a JointTrajectory controller in ROS 2. We also provide an integration with the Open Motion Planning Library (OMPL), a collision avoidance module, and tools for procedural environment generation. Our work enables the development and benchmarking of underwater multi-robot motion planning in dynamic environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">agrawal2025mrangler</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Underwater Multi-Robot Simulation and Motion Planning in Angler}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Agrawal, Akshaya and Palmer, Evan and Kingston, Zachary and Hollinger, Geoffrey A.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/MTS OCEANS Conference}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Brest, France}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="chengao2025diffsim" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">RoboSoft</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/robosoft25-480.webp 480w,/assets/img/publication_preview/robosoft25-800.webp 800w,/assets/img/publication_preview/robosoft25-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/robosoft25.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="robosoft25.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="col-sm-10"> <div class="title">Physics-Grounded Differentiable Simulation for Soft Growing Robots</div> <div class="author"> <a href="/members/lucas">Lucas Chen<sup>*</sup></a>, <a href="/members/yitian">Yitian Gao<sup>*</sup></a>, Sicheng Wang, Francesco Fuentes, <a href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=241064" class="nonmember" rel="external nofollow noopener" target="_blank">Laura H. Blumenschein</a>, and <a href="/members/kingston">Zachary Kingston</a> </div> <div class="periodical"> <em>In IEEE-RAS International Conference on Soft Robotics</em> </div> <div class="periodical"> To Appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2501.17963" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/CoMMALab/DiffVineSimPy" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Soft-growing robots (i.e., vine robots) are a promising class of soft robots that allow for navigation and growth in tightly confined environments. However, these robots remain challenging to model and control due to the complex interplay of the inflated structure and inextensible materials, which leads to obstacles for autonomous operation and design optimization. Although there exist simulators for these systems that have achieved qualitative and quantitative success in matching high-level behavior, they still often fail to capture realistic vine robot shapes using simplified parameter models and have difficulties in high-throughput simulation necessary for planning and parameter optimization. We propose a differentiable simulator for these systems, enabling the use of the simulator "in-the-loop" of gradient-based optimization approaches to address the issues listed above. With the more complex parameter fitting made possible by this approach, we experimentally validate and integrate a closed-form nonlinear stiffness model for thin-walled inflated tubes based on a first-principles approach to local material wrinkling. Our simulator also takes advantage of data-parallel operations by leveraging existing differentiable computation frameworks, allowing multiple simultaneous rollouts. We demonstrate the feasibility of using a physics-grounded nonlinear stiffness model within our simulator, and how it can be an effective tool in sim-to-real transfer. We provide our implementation open source.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chengao2025diffsim</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Physics-Grounded Differentiable Simulation for Soft Growing Robots}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Lucas and Gao, Yitian and Wang, Sicheng and Fuentes, Francesco and Blumenschein, Laura H. and Kingston, Zachary}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE-RAS International Conference on Soft Robotics}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <a name="ramsey2024" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA7900"> <a href="https://roboticsconference.org/" rel="external nofollow noopener" target="_blank"> RSS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Collision-Affording Point Trees: SIMD-Amenable Nearest Neighbors for Fast Collision Checking</div> <div class="author"> <a href="https://claytonwramsey.com" class="nonmember" rel="external nofollow noopener" target="_blank">Clayton W. Ramsey</a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In Robotics: Science and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2406.02807" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=BzDKdrU1VpM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://claytonwramsey.com/blog/captree" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/kavrakilab/vamp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.15607/RSS.2024.XX.038" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Motion planning against sensor data is often a critical bottleneck in real-time robot control. For sampling-based motion planners, which are effective for high-dimensional systems such as manipulators, the most time-intensive component is collision checking. We present a novel spatial data structure, the collision-affording point tree (CAPT): an exact representation of point clouds that accelerates collision-checking queries between robots and point clouds by an order of magnitude, with an average query time of less than 10 nanoseconds on 3D scenes comprising thousands of points. With the CAPT, sampling-based planners can generate valid, high-quality paths in under a millisecond, with total end-to-end computation time faster than 60 FPS, on a single thread of a consumer-grade CPU. We also present a point cloud filtering algorithm, based on space-filling curves, which reduces the number of points in a point cloud while preserving structure. Our approach enables robots to plan at real-time speeds in sensed environments, opening up potential uses of planning for high-dimensional systems in dynamic, changing, and unmodeled environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ramsey2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramsey, Clayton W. and Kingston, Zachary and Thomason, Wil and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collision-Affording Point Trees: SIMD-Amenable Nearest Neighbors for Fast Collision Checking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Robotics: Science and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15607/RSS.2024.XX.038}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="thomason2024vamp" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#daaa00"> <a href="https://ieee-icra.org" rel="external nofollow noopener" target="_blank"> ICRA </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Motions in Microseconds via Vectorized Sampling-Based Planning</div> <div class="author"> <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.14545" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/kavrakilab/vamp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/ICRA57147.2024.10611190" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Modern sampling-based motion planning algorithms typically take between hundreds of milliseconds to dozens of seconds to find collision-free motions for high degree-of-freedom problems. This paper presents performance improvements of more than 500x over the state-of-the-art, bringing planning times into the range of microseconds and solution rates into the range of kilohertz, without specialized hardware. Our key insight is how to exploit fine-grained parallelism within sampling-based planners, providing generality-preserving algorithmic improvements to any such planner and significantly accelerating critical subroutines, such as forward kinematics and collision checking. We demonstrate our approach over a diverse set of challenging, realistic problems for complex robots ranging from 7 to 14 degrees-of-freedom. Moreover, we show that our approach does not require high-power hardware by also evaluating on a low-power single-board computer. The planning speeds demonstrated are fast enough to reside in the range of control frequencies and open up new avenues of motion planning research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">thomason2024vamp</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Thomason, Wil and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Motions in Microseconds via Vectorized Sampling-Based Planning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8749--8756}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA57147.2024.10611190}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="Goues2024" class="anchor"></a> <div class="col col-sm-2 abbr"> </div> <div class="col-sm-10"> <div class="title">Software Engineering for Robotics: Future Research Directions; Report from the 2023 Workshop on Software Engineering for Robotics</div> <div class="author"> Claire Le Goues, Sebastian Elbaum, David Anthony, Z. Berkay Celik, Mauricio Castillo-Effen, Nikolaus Correll, Pooyan Jamshidi, Morgan Quigley, Trenton Tabor, and Qi Zhu </div> <div class="periodical"> </div> <div class="periodical"> Invited Contributor </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2401.12317.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">Goues2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Software Engineering for Robotics: Future Research Directions; Report from the 2023 Workshop on Software Engineering for Robotics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Goues, Claire Le and Elbaum, Sebastian and Anthony, David and Celik, Z. Berkay and Castillo-Effen, Mauricio and Correll, Nikolaus and Jamshidi, Pooyan and Quigley, Morgan and Tabor, Trenton and Zhu, Qi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2401.12317}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Invited Contributor}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="Ramsey2024wksp" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#505050"> <div> Workshop </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Dynamic Motion Planning from Perception via Accelerated Point Cloud Collision Checking</div> <div class="author"> <a href="https://claytonwramsey.com" class="nonmember" rel="external nofollow noopener" target="_blank">Clayton W. Ramsey</a>, <a href="/members/kingston">Zachary Kingston<sup>*</sup></a>, <a href="https://wbthomason.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Wil Thomason<sup>*</sup></a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE ICRA 2024 Workshop—Agile Robotics: From Perception to Dynamic Action</em> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Ramsey2024wksp</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramsey, Clayton W. and Kingston, Zachary and Thomason, Wil and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Motion Planning from Perception via Accelerated Point Cloud Collision Checking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE ICRA 2024 Workshop---Agile Robotics: From Perception to Dynamic Action}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <a name="kingston2022robowflex" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA9200"> <a href="https://ieee-iros.org/" rel="external nofollow noopener" target="_blank"> IROS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Robowflex: Robot Motion Planning with MoveIt Made Easy</div> <div class="author"> <a href="/members/kingston">Zachary Kingston</a> and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Nominated</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://kavrakilab.org/publications/kingston2022-robowflex.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://player.vimeo.com/video/760062092?h=68a0b835cf&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://www.youtube.com/watch?v=mPDE3QSkLJ0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a> <a href="https://github.com/KavrakiLab/robowflex" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/IROS47612.2022.9981698" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Nominated for Best Paper for Industrial Robotics Research for Practicality.</p> </div> <div class="abstract hidden"> <p>Robowflex is a software library for robot motion planning in industrial and research applications, leveraging the popular MoveIt library and Robot Operating System (ROS) middleware. Robowflex takes advantage of the ease of motion planning with MoveIt while providing an augmented API to craft and manipulate motion planning queries within a single program. Robowflex’s high-level API simplifies many common use-cases while still providing access to the underlying MoveIt library. Robowflex is particularly useful for 1) developing new motion planners, 2) evaluation of motion planners, and 3) complex problems that use motion planning (e.g., task and motion planning). Robowflex also provides visualization capabilities, integrations to other robotics libraries (e.g., DART and Tesseract), and is complimentary to many other robotics packages. With our library, the user does not need to be an expert at ROS or MoveIt in order to set up motion planning queries, extract information from results, and directly interface with a variety of software components. We provide a few example use-cases that demonstrate its efficacy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kingston2022robowflex</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robowflex: Robot Motion Planning with MoveIt Made Easy}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3108--3114}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS47612.2022.9981698}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <a name="chamzas2021mbm" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#BB921F"> <a href="https://www.ieee-ras.org/publications/ra-l" rel="external nofollow noopener" target="_blank"> RA-L </a> </abbr> </div> <div class="col-sm-10"> <div class="title">MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets</div> <div class="author"> <a href="https://cchamzas.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Constantinos Chamzas</a>, <a href="https://carlosquinterop.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Carlos Quintero-Peña</a>, <a href="/members/kingston">Zachary Kingston</a>, <a href="https://www.aorthey.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Andreas Orthey</a>, <a href="https://dannyrakita.net/" class="nonmember" rel="external nofollow noopener" target="_blank">Daniel Rakita</a>, Michael Gleicher, <a href="https://www.user.tu-berlin.de/mtoussai/" class="nonmember" rel="external nofollow noopener" target="_blank">Marc Toussaint</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://kavrakilab.org/publications/chamzas2022-motion-bench-maker.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=t96Py0QX0NI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://www.youtube.com/watch?v=dCxXZWGQIlQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a> <a href="https://github.com/KavrakiLab/motion_bench_maker" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/LRA.2021.3133603" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Recently, there has been a wealth of development in motion planning for robotic manipulationnew motion planners are continuously proposed, each with its own unique set of strengths and weaknesses. However, evaluating these new planners is challenging, and researchers often create their own ad-hoc problems for benchmarking, which is time-consuming, prone to bias, and does not directly compare against other state-of-the-art planners. We present MotionBenchMaker, an open-source tool to generate benchmarking datasets for realistic robot manipulation problems. MotionBenchMaker is designed to be an extensible, easy-to-use tool that allows users to both generate datasets and benchmark them by comparing motion planning algorithms. Empirically, we show the benefit of using MotionBenchMaker as a tool to procedurally generate datasets which helps in the fair evaluation of planners. We also present a suite of over 40 prefabricated datasets, with 5 different commonly used robots in 8 environments, to serve as a common ground for future motion planning research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chamzas2021mbm</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chamzas, Constantinos and Quintero-Peña, Carlos and Kingston, Zachary and Orthey, Andreas and Rakita, Daniel and Gleicher, Michael and Toussaint, Marc and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning Datasets}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{882--889}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2021.3133603}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="moll2021hyper" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA9200"> <a href="https://ieee-iros.org/" rel="external nofollow noopener" target="_blank"> IROS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization</div> <div class="author"> <a href="https://moll.ai/" class="nonmember" rel="external nofollow noopener" target="_blank">Mark Moll</a>, <a href="https://cchamzas.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Constantinos Chamzas</a>, <a href="/members/kingston">Zachary Kingston</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://kavrakilab.org/publications/moll2021hyperplan.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/KavrakiLab/hyperplan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.1109/IROS51168.2021.9636651" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Over the years, many motion planning algorithms have been proposed. It is often unclear which algorithm might be best suited for a particular class of problems. The problem is compounded by the fact that algorithm performance can be highly dependent on parameter settings. This paper shows that hyperparameter optimization is an effective tool in both algorithm selection and parameter tuning over a given set of motion planning problems. We present different loss functions for optimization that capture different notions of optimality. The approach is evaluated on a broad range of scenes using two different manipulators, a Fetch and a Baxter. We show that optimized planning algorithm performance significantly improves upon baseline performance and generalizes broadly in the sense that performance improvements carry over to problems that are very different from the ones considered during optimization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">moll2021hyper</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moll, Mark and Chamzas, Constantinos and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2511-2518}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS51168.2021.9636651}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <a name="baker2017r2" class="anchor"></a> <div class="col col-sm-2 abbr"> </div> <div class="col-sm-10"> <div class="title">Robonaut 2 and You: Specifying and Executing Complex Operations</div> <div class="author"> William Baker, <a href="/members/kingston">Zachary Kingston</a>, <a href="https://moll.ai/" class="nonmember" rel="external nofollow noopener" target="_blank">Mark Moll</a>, Julia Badger, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE Workshop on Advanced Robotics and its Social Impacts</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://kavrakilab.org/publications/baker2017robonaut-2-and-you.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://player.vimeo.com/video/287250170?loop=1&amp;color=ffffff&amp;byline=0&amp;portrait=0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://doi.org/10.1109/ARSO.2017.8025204" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Crew time is a precious resource due to the expense of trained human operators in space. Efficient caretaker robots could lessen the manual labor load required by frequent vehicular and life support maintenance tasks, freeing astronaut time for scientific mission objectives. Humanoid robots can fluidly exist alongside human counterparts due to their form, but they are complex and high-dimensional platforms. This paper describes a system that human operators can use to maneuver Robonaut 2 (R2), a dexterous humanoid robot developed by NASA to research co-robotic applications. The system includes a specification of constraints used to describe operations, and the supporting planning framework that solves constrained problems on R2 at interactive speeds. The paper is developed in reference to an illustrative, typical example of an operation R2 performs to highlight the challenges inherent to the problems R2 must face. Finally, the interface and planner is validated through a case-study using the guiding example on the physical robot in a simulated microgravity environment. This work reveals the complexity of employing humanoid caretaker robots and suggest solutions that are broadly applicable.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">baker2017r2</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Baker, William and Kingston, Zachary and Moll, Mark and Badger, Julia and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robonaut 2 and You: Specifying and Executing Complex Operations}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Workshop on Advanced Robotics and its Social Impacts}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Austin, TX}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ARSO.2017.8025204}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> CoMMA Lab @ <a href="https://www.purdue.edu/" rel="external nofollow noopener" target="_blank">Purdue University</a>, <a href="https://www.cs.purdue.edu/" rel="external nofollow noopener" target="_blank">Department of Computer Science</a>. © Copyright 2025. Last updated: June 10, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>