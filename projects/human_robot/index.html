<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Human-Robot Collaboration | CoMMA Lab @ Purdue </title> <meta name="author" content=" "> <meta name="description" content="The Computational Robot Motion and Autonomy Lab at Purdue University "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://commalab.github.io/projects/human_robot/"> <script src="/assets/js/theme.js?ca131c86afeddc68f0e9d3278afbc9b8"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> CoMMA Lab @ Purdue </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code </a> </li> <li class="nav-item "> <a class="nav-link" href="/classes/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/join">Join </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Human-Robot Collaboration</h1> <p class="post-description"></p> </header> <div class="big-profile float-right"> <figure> <video src="/assets/video/hri.webm" class="img-fluid z-depth-1" width="100%" height="auto" autoplay controls loop muted></video> </figure> </div> <article> <p>Humans are hard to model and predict; thus, it is hard for a robot to consider how other people in the environment may act in its decision-making process. Finding efficient and effective ways to model human behavior to maintain the safety of people around a robot or to allow a robot to fluently collaborate with other people (or perhaps even other agents) is critical to deploying robots outside controlled environments such as the lab or factory.</p> <p>Moreover, as robots become more capable agents and enter the real world, systems today appear in the workplace, home, and public spaces. Ethical considerations of how robots <em>should</em> operate are trailing behind algorithmic advances, and these advances do not necessarily consider the other people the robot is working around explicitly. Suppose the algorithms that control a robot’s behavior are agnostic to human concerns. In that case, they will be (un)intentionally exploited by malicious, unethical, or ignorant actors to violate privacy, injure and disturb people, and further increase inequity.</p> </article> <br style="clear:both"> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <a name="guo2025castl" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#daaa00"> <a href="https://ieee-icra.org" rel="external nofollow noopener" target="_blank"> ICRA </a> </abbr> </div> <div class="col-sm-10"> <div class="title">CaStL: Constraints as Specifications through LLM Translation for Long-Horizon Task and Motion Planning</div> <div class="author"> <a href="https://www.whguo.me/" class="nonmember" rel="external nofollow noopener" target="_blank">Weihang Guo</a>, <a href="/members/kingston">Zachary Kingston</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation</em> </div> <div class="periodical"> To Appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2410.22225" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) have demonstrated remarkable ability in long-horizon Task and Motion Planning (TAMP) by translating clear and straightforward natural language problems into formal specifications such as the Planning Domain Definition Language (PDDL). However, real-world problems are often ambiguous and involve many complex constraints. In this paper, we introduce Constraints as Specifications through LLMs (CaStL), a framework that identifies constraints such as goal conditions, action ordering, and action blocking from natural language in multiple stages. CaStL translates these constraints into PDDL and Python scripts, which are solved using an custom PDDL solver. Tested across three PDDL domains, CaStL significantly improves constraint handling and planning success rates from natural language specification in complex scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">guo2025castl</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{CaStL}: Constraints as Specifications through {LLM} Translation for Long-Horizon Task and Motion Planning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guo, Weihang and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2410.22225}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.RO}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{To Appear}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <a name="meng2024icra40" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#505050"> <div> Abstract </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Perception-aware Planning for Robotics: Challenges and Opportunities</div> <div class="author"> <a href="https://www.linkedin.com/in/qingxi-meng-0b733a125/" class="nonmember" rel="external nofollow noopener" target="_blank">Qingxi Meng</a>, <a href="https://carlosquinterop.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Carlos Quintero-Peña</a>, <a href="/members/kingston">Zachary Kingston</a>, <a href="https://unhelkar.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Vaibhav Unhelkar</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In 40th Anniversary of the IEEE Conference on Robotics and Automation (ICRA@40)</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://kavrakilab.org/publications/meng2024-review.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this work, we argue that new methods are needed to generate robot motion for navigation or manipulation while effectively achieving perception goals. We support our argument by conducting experiments with a simulated robot that must accomplish a primary task, such as manipulation or navigation, while concurrently monitoring an object in the environment. Our preliminary study demonstrates that a decoupled approach fails to achieve high success in either action-focused motion generation or perception goals, motivating further developments of approaches that holistically consider both goals.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">meng2024icra40</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Meng, Qingxi and Quintero-Peña, Carlos and Kingston, Zachary and Unhelkar, Vaibhav and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Perception-aware Planning for Robotics: Challenges and Opportunities}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{40th Anniversary of the IEEE Conference on Robotics and Automation (ICRA@40)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <a name="Meng2024wksp" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#505050"> <div> Workshop </div> </abbr> </div> <div class="col-sm-10"> <div class="title">Monitoring Constraints for Robotic Tutors in Nurse Education: A Motion Planning Perspective</div> <div class="author"> <a href="https://www.linkedin.com/in/qingxi-meng-0b733a125/" class="nonmember" rel="external nofollow noopener" target="_blank">Qingxi Meng<sup>*</sup></a>, <a href="https://carlosquinterop.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Carlos Quintero-Peña<sup>*</sup></a>, <a href="/members/kingston">Zachary Kingston</a>, Nicole M. Fontenot, Shannan K. Hamlin, <a href="https://unhelkar.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Vaibhav Unhelkar</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE ICRA 2024 Workshop—Workshop on Nursing Robotics</em> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Meng2024wksp</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Meng, Qingxi and Quintero-Peña, Carlos and Kingston, Zachary and Fontenot, Nicole M. and Hamlin, Shannan K. and Unhelkar, Vaibhav and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Monitoring Constraints for Robotic Tutors in Nurse Education: A Motion Planning Perspective}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE ICRA 2024 Workshop---Workshop on Nursing Robotics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <a name="shome2023privacy" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#DA9200"> <a href="https://ieee-iros.org/" rel="external nofollow noopener" target="_blank"> IROS </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Robots as AI Double Agents: Privacy in Motion Planning</div> <div class="author"> <a href="https://www.rahulsho.me/" class="nonmember" rel="external nofollow noopener" target="_blank">Rahul Shome</a>, <a href="/members/kingston">Zachary Kingston</a>, and <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2308.03385.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://doi.org/10.1109/IROS55552.2023.10341460" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Robotics and automation are poised to change the landscape of home and work in the near future. Robots are adept at deliberately moving, sensing, and interacting with their environments. The pervasive use of this technology promises societal and economic payoffs due to its capabilities - conversely, the capabilities of robots to move within and sense the world around them is susceptible to abuse. Robots, unlike typical sensors, are inherently autonomous, active, and deliberate. Such automated agents can become AI double agents liable to violate the privacy of coworkers, privileged spaces, and other stakeholders. In this work we highlight the understudied and inevitable threats to privacy that can be posed by the autonomous, deliberate motions and sensing of robots. We frame the problem within broader sociotechnological questions alongside a comprehensive review. The privacy-aware motion planning problem is formulated in terms of cost functions that can be modified to induce privacy-aware behavior - preserving, agnostic, or violating. Simulated case studies in manipulation and navigation, with altered cost functions, are used to demonstrate how privacy-violating threats can be easily injected, sometimes with only small changes in performance (solution path lengths). Such functionality is already widely available. This preliminary work is meant to lay the foundations for near-future, holistic, interdisciplinary investigations that can address questions surrounding privacy in intelligent robotic behaviors determined by planning algorithms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shome2023privacy</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shome, Rahul and Kingston, Zachary and Kavraki, Lydia E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robots as AI Double Agents: Privacy in Motion Planning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2861-2868}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IROS55552.2023.10341460}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <a name="wells2021icra" class="anchor"></a> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#daaa00"> <a href="https://ieee-icra.org" rel="external nofollow noopener" target="_blank"> ICRA </a> </abbr> </div> <div class="col-sm-10"> <div class="title">Finite Horizon Synthesis for Probabilistic Manipulation Domains</div> <div class="author"> <a href="https://andrewmw94.github.io/" class="nonmember" rel="external nofollow noopener" target="_blank">Andrew M. Wells</a>, <a href="/members/kingston">Zachary Kingston</a>, <a href="https://mortezalahijanian.com/" class="nonmember" rel="external nofollow noopener" target="_blank">Morteza Lahijanian</a>, <a href="https://profiles.rice.edu/faculty/lydia-e-kavraki" class="nonmember" rel="external nofollow noopener" target="_blank">Lydia E. Kavraki</a>, and <a href="https://www.cs.rice.edu/~vardi/" class="nonmember" rel="external nofollow noopener" target="_blank">Moshe Y. Vardi</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://www.kavrakilab.org/publications/wells2021-finite-horizon-synthesis.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://doi.org/10.1109/ICRA48506.2021.9561297" rel="external nofollow noopener" target="_blank"> <i class="ai ai-doi ml-1"> </i> </a> </div> <div class="abstract hidden"> <p>Robots have begun operating and collaborating with humans in industrial and social settings. This collaboration introduces challenges: the robot must plan while taking the human’s actions into account. In prior work, the problem was posed as a 2-player deterministic game, with a limited number of human moves. The limit on human moves is unintuitive, and in many settings determinism is undesirable. In this paper, we present a novel planning method for collaborative human-robot manipulation tasks via probabilistic synthesis. We introduce a probabilistic manipulation domain that captures the interaction by allowing for both robot and human actions with states that represent the configurations of the objects in the workspace. The task is specified using Linear Temporal Logic over finite traces (LTLf). We then transform our manipulation domain into a Markov Decision Process (MDP) and synthesize an optimal policy to satisfy the specification on this MDP. We present two novel contributions: a formalization of probabilistic manipulation domains allowing us to apply existing techniques and a comparison of different encodings of these domains. Our framework is validated on a physical UR5 robot.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wells2021icra</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wells, Andrew M. and Kingston, Zachary and Lahijanian, Morteza and Kavraki, Lydia E. and Vardi, Moshe Y.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Finite Horizon Synthesis for Probabilistic Manipulation Domains}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA48506.2021.9561297}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6336--6342}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> CoMMA Lab @ <a href="https://www.purdue.edu/" rel="external nofollow noopener" target="_blank">Purdue University</a>, <a href="https://www.cs.purdue.edu/" rel="external nofollow noopener" target="_blank">Department of Computer Science</a>. © Copyright 2025. Last updated: July 16, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>